{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-23T21:57:30.039938Z",
     "start_time": "2024-11-23T21:57:28.403312Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "factify_train = pd.read_csv(\"/Users/sakdag/Downloads/public_folder/train.csv\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T21:57:57.306557Z",
     "start_time": "2024-11-23T21:57:57.301142Z"
    }
   },
   "cell_type": "code",
   "source": "factify_train[\"Category\"].value_counts()",
   "id": "588922424afe3fe4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Support_Text               7000\n",
       "Insufficient_Multimodal    7000\n",
       "Support_Multimodal         7000\n",
       "Insufficient_Text          7000\n",
       "Refute                     7000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T21:58:40.357838Z",
     "start_time": "2024-11-23T21:58:39.962770Z"
    }
   },
   "cell_type": "code",
   "source": "factify_val = pd.read_csv(\"/Users/sakdag/Downloads/public_folder/val.csv\")",
   "id": "2a7cf26b899db6fa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T21:58:46.417726Z",
     "start_time": "2024-11-23T21:58:46.411963Z"
    }
   },
   "cell_type": "code",
   "source": "factify_val[\"Category\"].value_counts()",
   "id": "a6e834ff1ec937e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Support_Multimodal         1500\n",
       "Refute                     1500\n",
       "Support_Text               1500\n",
       "Insufficient_Text          1500\n",
       "Insufficient_Multimodal    1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T22:09:37.661215Z",
     "start_time": "2024-11-23T22:06:37.363353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensuring consistent language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Example DataFrame\n",
    "# factify_train = pd.DataFrame({'claim': ['This is an English sentence.', 'Ceci est une phrase française.', 'Este es un texto en español.', ...]})\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Use tqdm to show progress\n",
    "tqdm.pandas(desc=\"Detecting languages\")\n",
    "\n",
    "# Apply language detection with progress bar\n",
    "factify_train['language'] = factify_train['document'].progress_apply(detect_language)\n",
    "\n",
    "# Get counts per language\n",
    "language_counts = factify_train['language'].value_counts()\n",
    "\n",
    "# Display the results\n",
    "print(language_counts)\n"
   ],
   "id": "466cc774bfc81130",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting languages: 100%|██████████| 35000/35000 [03:00<00:00, 194.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en         34969\n",
      "nl            11\n",
      "hi             7\n",
      "de             6\n",
      "es             2\n",
      "it             1\n",
      "fr             1\n",
      "unknown        1\n",
      "id             1\n",
      "bn             1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T12:38:08.667236Z",
     "start_time": "2024-12-31T12:38:08.662573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def modify_keys_in_pkl(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Reads a .pkl file, modifies its keys by replacing backslashes (\\\\) with slashes (/),\n",
    "    and writes the updated data back to a new .pkl file.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input .pkl file.\n",
    "        output_file (str): Path to the output .pkl file.\n",
    "    \"\"\"\n",
    "    # Ensure the input file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file {input_file} does not exist.\")\n",
    "\n",
    "    # Read the data from the input .pkl file\n",
    "    with open(input_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "\n",
    "    # Ensure the data is a dictionary\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(\"The .pkl file must contain a dictionary.\")\n",
    "\n",
    "    # Modify the keys in the dictionary\n",
    "    modified_data = {\n",
    "        (key.replace('\\\\', '/') if isinstance(key, str) else key): value\n",
    "        for key, value in data.items()\n",
    "    }\n",
    "\n",
    "    # Write the modified data back to a new .pkl file\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(modified_data, file)\n",
    "\n",
    "    print(f\"Modified keys saved to {output_file}\")"
   ],
   "id": "a7c3317a8918e94c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T12:38:22.814426Z",
     "start_time": "2024-12-31T12:38:22.799868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.path_utils import get_project_root\n",
    "\n",
    "project_root = get_project_root()\n",
    "old_pkl = os.path.join(project_root, \"evidence_feature_old.pkl\")\n",
    "new_pk = os.path.join(project_root, \"evidence_feature.pkl\")"
   ],
   "id": "f3333b12c399d5b8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T12:38:29.196313Z",
     "start_time": "2024-12-31T12:38:22.915685Z"
    }
   },
   "cell_type": "code",
   "source": "modify_keys_in_pkl(old_pkl, new_pk)",
   "id": "3c39720a1eb008e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified keys saved to /Users/sakdag/Desktop/masters/multimodal-misinformation-detection/evidence_feature.pkl\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T12:42:49.272660Z",
     "start_time": "2024-12-31T12:42:46.103728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(new_pk, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    print(list(data.keys())[0])\n",
    "    print(data[list(data.keys())[0]])\n",
    "    print(list(data.keys())[-1])\n",
    "    print(data[list(data.keys())[-1]])\n",
    "    print(len(data))"
   ],
   "id": "e05317c21db25b9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/factify/extracted/images/test/0_evidence.jpg\n",
      "tensor([0.0000, 0.0000, 0.0750,  ..., 0.2198, 0.0000, 0.0027])\n",
      "data/raw/factify/extracted/images/train/9_evidence.jpg\n",
      "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0383, 0.0000])\n",
      "41256\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b8497941bc652cfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
